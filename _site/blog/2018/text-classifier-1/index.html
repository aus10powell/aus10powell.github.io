<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Text Classifier Part 1: CNN Classifier Using Pytorch</title>
<meta name="description" content="Estimated read time: 5 min">

<link rel="stylesheet" href="/css/main.css">
<link rel="canonical" href="https://aus10powell.github.io//blog/2018/text-classifier-1/">
<link rel="alternate" type="application/rss+xml" title="Austin's Site" href="https://aus10powell.github.io//feed.xml" />


<!-- Mathjax Support (for LATEX) -->
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>


</head>
<body>
  <header class="site-header">
  <div class="container">
    <input type="checkbox" id="toggleNavbar">
    <!--<h1 class="logo"><a href="/">end2<span>end</span> <small>v2.0</small></a></h1>
    <label for="toggleNavbar" role="button" class="toggle-navbar-button">
      <i class="icon icon-menu"></i>
      <i class="icon icon-cross"></i>
    -->
    </label>
    <nav class="navbar">
      <ul>
        <li><a href="/" title="Home">Home</a></li>
        
          <li><a href="/about" title="About">About</a></li>
        
          <li><a href="/blog" title="Blog">Blog</a></li>
        
        <!--
        <li><a href="https://github.com/aus10powell/archive/master.zip" title="Download">Download</a></li>
        -->
        <li><a href="/feed.xml" target="_blank"><i class="icon icon-rss"></i></a></li>

      </ul>
    </nav>
  </div>
</header>


<main class="main-container">
  <div class="container">
    <article role="article" class="post">

  <div class="card">
    <header class="post-header">
      <h1 class="post-title">Text Classifier Part 1: CNN Classifier Using Pytorch</h1>
      <em class="post-meta">
        <time>Sep 1, 2018</time>
      </em>
    </header>

    <div class="post-content">
      
        <figure class="post-thumbnail ">
          <img src="../../../images/2018-09-01-text-classifier-part-1/cnn-image-thumbnail.png" alt="Text Classifier Part 1: CNN Classifier Using Pytorch">
        </figure>
      
      <p><em>Estimated read time: 5 min</em></p>

<h2 id="intro">Intro</h2>

<p>Originally I was motivated to replicate the work of researches from the 2016 paper <a href="https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf">Hierarchical Attention Networks for Document Classification</a>. However, after reading through the <a href="https://richliao.github.io/supervised/classification/2016/11/26/textclassifier-convolutional/">excellent posts by Richard Liao</a>, I decide to roughly follow his journey in order to get more familiar with Pytorch. As I have learned, Tensorflow, and by extension Keras, for multiple reasons (not necessarily with user use in mind) have many more resources available. You can read a breakdown for choosing Keras over PyTorch <a href="https://www.reddit.com/r/MachineLearning/comments/6bicfo/d_keras_vs_pytorch/">Here</a>. Another option if speed of implementation were a large issue would be to use the <a href="https://www.fast.ai/">FastAI library headed by Jeremey Howard</a></p>

<p><br /><br /></p>

<p>This was also an exploration into <a href="https://torchtext.readthedocs.io/en/latest/">TorchText</a> which I also prefer to Keras. Similar to Keras has some useful features:</p>
<ul>
  <li>Data loaders</li>
  <li>Batch generators</li>
  <li>Easy loading of GLove and FastText embeddings</li>
  <li>Easy loading of datasets (such as the IMBD ratings dataset)</li>
</ul>

<p>There are base NN frameworks that can be used. A recursive or recurrent neural network or convolutional neural network could all be used for the exact same task.</p>

<h3 id="cnn">CNN</h3>
<p>Due to the different convolutions not being dependent on each other is one of the primary reasons for speedup. This frame-work is well-suited for sentence classification (however may not be the best for larger corpora) <a href="https://arxiv.org/pdf/1702.01923.pdf">Comparative Study of CNN and RNN for Natural Language Processing</a>. Although due to faster training and therefore faster iteration, many researchers have found performance losses are negligible.</p>

<h3 id="loss-function">Loss Function:</h3>
<p><script type="math/tex">L(x,y) = \sum{x_i}</script></p>

<h2 id="dataset">Dataset</h2>
<p>From the UCI Machine Learning Repository <a href="https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Druglib.com%29">Here</a>. Although the dataset has several attributes, I’ll be focusing on patient reviews on specific drugs along with related conditions and their ratings. Although the ratings are ordinal, they will be treated as independent.</p>

<h1 id="code">Code</h1>

<p><strong>Initialize TorchText Data Parameters</strong></p>
<td><pre>
import spacy
import torchtext
# I recommend to use at least the medium-sized spacy embeddings
nlp = spacy.load('en_core_web_md')

def spacy_tokenizer(text): # create a tokenizer function
    """Simple tokenizer. Returns tokenized text of corpus as list."""
    return [tok.text) for tok in nlp.tokenizer(str(text))]

# Define a Field class: this is a class that contains information on how you want the data preprocessed.
TEXT = torchtext.data.Field(sequential=True,
                            tokenize=spacy_tokenizer,
                            batch_first=True,
                            # kept fix_length relatively conservative because most text is fairly short
                            fix_length=100,
                            include_lengths=True,
                            lower=True
                           )
LABEL = torchtext.data.Field(sequential=False,
                             is_target=True,
                            # use_vocab=False
                            )
</pre></td>

<h2 id="data-prep">Data Prep</h2>

<td><pre>
# Xavier uniform initialization is for tokens that are not seen in the corpus. This particular
# initialization enables you to have the same variance input as you do output from the word vectors.

TEXT.build_vocab(train,val,test, vectors=GloVe(name='6B', dim=300), unk_init=torch.nn.init.xavier_uniform_) # fills in uniform for unknown words
LABEL.build_vocab(train,val,test,)

batch_size = 32
train_iter, valid_iter, test_iter = torchtext.data.BucketIterator.splits(
                                                                    (train, val, test), sort_key=lambda x: len(x.text),
                                                                    batch_size=batch_size,
                                                                    sort_within_batch=True, # necessary to use in pack_pad_sequence
                                                                    shuffle=True,
                                                                    repeat = False,
                                                                    device=device)

</pre></td>

<h3 id="model">Model</h3>

<h3 id="additional-resourcespaper-references">Additional Resources/Paper References:</h3>
<ul>
  <li><a href="https://www.youtube.com/watch?v=vYJtZwoO9Rw&amp;t=0s&amp;index=13&amp;list=PLlJy-eBtNFt4CSVWYqscHDdP58M3zFHIG">Convolutional Neural Networks (for NLP) Stanford lecture</a></li>
  <li><a href="https://www.aclweb.org/anthology/D13-1176">Recurrent Continuous Translation Models</a></li>
  <li><a href="https://arxiv.org/abs/1510.03820">A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification</a></li>
  <li><a href="https://arxiv.org/pdf/1510.03820.pdf">Neural Networks for Sentence Classification</a></li>
</ul>

    </div>

    
<hr>

<aside id="comments" class="disqus">
  <h3><i class="icon icon-comments-o"></i> Comments</h3>
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function() {
      this.page.url = 'https://aus10powell.github.io//blog/2018/text-classifier-1/';
      this.page.identifier = '/blog/2018/text-classifier-1';
    };
    (function() {
      var d = document,
      s = d.createElement('script');
      s.src = '//austins-site.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })
    ();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</aside>


  </div>

</article>

  </div>
</main>

<footer class="site-footer">
  <div class="container">
    <ul class="social">
  <li><a href="https://github.com/aus10powell" target="_blank"><i class="icon icon-github"></i></a></li>
  <li><a href="https://twitter.com/aus10_powers" target="_blank"><i class="icon icon-twitter"></i></a></li>
  <li><a href="https://www.linkedin.com/in/aus10powell/" target="_blank"><i class="icon icon-linkedin"></i></a></li>
</ul>

    <p class="txt-medium-gray">
      <small>&copy;2019 All rights reserved. Made with <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> and ♥</small>
    </p>
  </div>
</footer>


  <!--<a href="https://github.com/aus10powell" target="_blank" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#337ab7; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a> -->
</body>
</html>
