---
layout: single
title:  "Medium Post on Word Embedding Comparisons for Disease Name Entity Recognition"
date:   2018-10-31
comments: true
# image: /assets/images/poizon_plants/poizon_plants_app.jpg
categories: General
description: "An overview of out-of-box benefits evaluated on open-source health dataset"
---

This is a quick comparison of word embeddings for a Named Entity Recognition (NER) task with diseases and adverse conditions. It is not in any way exhaustive and motivated primarily by wanted to try the ELMo embeddings that have gained popularity this year in a health natural language processing task.

I compared different word embedding techniques for Disease Named Entity Recognition (DNER) task. I focused on three popular methods, i.e., word2vec, GloVe, and fastText, and evaluated their performance on a biomedical text corpus.

I conducted experiments on two datasets using various machine learning algorithms and evaluation metrics to compare the performance of the word embeddings. The results showed that all three methods performed well for DNER task, and the choice of embedding method had minimal impact on the models' performance.

However, my study also revealed that combining different embedding techniques and incorporating domain-specific features could further improve the performance of the models. I suggested that further research is needed to explore the use of hybrid models for biomedical named entity recognition tasks.

Overall, the significance of selecting appropriate word embedding techniques for natural language processing tasks and how combining multiple techniques can enhance the performance of the models.

You can read in more detail here: [Word Embedding Comparison For Disease Named Entity Recognition](https://medium.com/analytics-vidhya/word-embedding-comparison-for-disease-named-entity-recognition-a99850653e1c)