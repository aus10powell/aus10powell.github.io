---
layout: single
title:  "2023 Papers"
date:   2023-01-01
comments: true
# image: /assets/images/poizon_plants/poizon_plants_app.jpg
categories: 2023 Papers 
description: "Papers Read in 2023"
keywords: research, ml, data-science, papers, nlp, audio, ai
show_date: true
words_per_minute: 300
---

**2023 Reading List**

## Audio
* [Self-supervised learning for infant cry analysis](https://arxiv.org/abs/2305.01578")
    * Self-supervised learning can be used to learn useful representations of infant cries from unlabeled data.
    * The self-supervised approach was able to achieve comparable performance to a supervised learning approach that was trained on a small amount of labeled data.
    * Self-supervised learning could be a valuable tool for developing new and improved infant cry analysis systems.
* [CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds](https://arxiv.org/abs/2305.00969")
    * The CryCeleb dataset is a large and diverse dataset of infant cry sounds.

## NLP
* [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/abs/1910.13461)
    * BART is a denoising autoencoder, which means that it is trained on a dataset of corrupted text. The corruptions can be simple, such as replacing words with random words, or more complex, such as removing words or sentences. BART is trained to reconstruct the original text from the corrupted text.
    * This training procedure helps BART to learn to represent the meaning of text, even when the text is corrupted. This makes BART well-suited for natural language generation, translation, and comprehension tasks.
* [Backpack Language Models](https://arxiv.org/abs/2305.16765)
    * Backpacks is a neural architecture that combines strong modeling performance with interpretability and control. It learns multiple sense vectors for each word, representing different aspects of the word, and allows for intervention and modification of these vectors to change the model's behavior. It outperforms larger models in lexical similarity evaluations and enables controllable text generation and debiasing through sense vector manipulation.

## ML
* [DeepHit: A Deep Learning Approach to Survival Analysis with Competing Risks
](http://medianetlab.ee.ucla.edu/papers/AAAI_2018_DeepHit) Time-to-event analysis is widely used in economics, finance, engineering, medicine and many other areas. Previous models rely on strong parametric assumptions that are often violated. DeepHit uses a deep neural network to learn the distribution of survival times directly. Comparisons with previous models on the basis of real and synthetic datasets demonstrate that DeepHit achieves statistically significant performance improvements.

### Large-Language Models
* [Parameter-Efficient Transfer Learning for NLP](http://proceedings.mlr.press/v97/houlsby19a/houlsby19a.pdf)
* [RLHF: Reinforcement Learning from Human Feedback (A blog by Chip Huyen)](https://huyenchip.com/2023/05/02/rlhf.html)