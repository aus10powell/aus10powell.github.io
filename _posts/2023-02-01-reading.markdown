---
layout: single
title:  "2023 Papers"
date:   2023-01-01
comments: true
# image: /assets/images/poizon_plants/poizon_plants_app.jpg
categories: 2023 Papers 
description: "Papers Read in 2023"
keywords: research, ml, data-science, papers, nlp, audio, ai
show_date: true
words_per_minute: 300
---

**2023 Reading List**

## Audio
* [Self-supervised learning for infant cry analysis](https://arxiv.org/abs/2305.01578")
    * Self-supervised learning can be used to learn useful representations of infant cries from unlabeled data.
    * The self-supervised approach was able to achieve comparable performance to a supervised learning approach that was trained on a small amount of labeled data.
    * Self-supervised learning could be a valuable tool for developing new and improved infant cry analysis systems.
* [CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds](https://arxiv.org/abs/2305.00969")
    * The CryCeleb dataset is a large and diverse dataset of infant cry sounds. This challenge has narrowed in on the task of distinguishing baby cries from each other.

## NLP
* [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/abs/1910.13461)
    * BART is a denoising autoencoder, which means that it is trained on a dataset of corrupted text. The corruptions can be simple, such as replacing words with random words, or more complex, such as removing words or sentences. BART is trained to reconstruct the original text from the corrupted text.
    * This training procedure helps BART to learn to represent the meaning of text, even when the text is corrupted. This makes BART well-suited for natural language generation, translation, and comprehension tasks.
* [Backpack Language Models](https://arxiv.org/abs/2305.16765)
    * Backpacks is a neural architecture that combines strong modeling performance with interpretability and control. It learns multiple sense vectors for each word, representing different aspects of the word, and allows for intervention and modification of these vectors to change the model's behavior. It outperforms larger models in lexical similarity evaluations and enables controllable text generation and debiasing through sense vector manipulation.
* 05/25/23
    * [State of GPT (a Youtube update by Microsoft)](https://www.youtube.com/watch?v=bZQun8Y4L2A&t=518s&ab_channel=MicrosoftDeveloper)

## Vision
* [YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors](https://arxiv.org/abs/2207.02696)
* [ByteTrack: Multi-Object Tracking by Associating Every Detection Box](https://arxiv.org/abs/2110.06864) To reduce missing detections and keep the persistence of trajectories, authors keep detection boxes and associate across every of them.
* [Object Detection for Dummies Part 3: R-CNN Family](https://lilianweng.github.io/posts/2017-12-31-object-recognition-part-3/) Good discussion on loss of object recognition.
* [A good overview of object Detection and Image Segmentation](https://www.oreilly.com/library/view/practical-machine-learning/9781098102357/ch04.html)

## ML (General)
* [DeepHit: A Deep Learning Approach to Survival Analysis with Competing Risks
](http://medianetlab.ee.ucla.edu/papers/AAAI_2018_DeepHit) Time-to-event analysis is widely used in economics, finance, engineering, medicine and many other areas. Previous models rely on strong parametric assumptions that are often violated. DeepHit uses a deep neural network to learn the distribution of survival times directly. Comparisons with previous models on the basis of real and synthetic datasets demonstrate that DeepHit achieves statistically significant performance improvements.

## ML Ops
* [Continuous Adaptation for Machine (Learning)](https://blog.tensorflow.org/2021/12/continuous-adaptation-for-machine.html)
* [Model training as a CI/CD system: Part I](https://cloud.google.com/blog/topics/developers-practitioners/model-training-cicd-system-part-i)
* [Model training as a CI/CD system: Part II](https://cloud.google.com/blog/topics/developers-practitioners/model-training-cicd-system-part-ii)
    * The process of building a CI/CD system specifically for model training.
    * Key components such as data management, environment setup, model training pipeline, and version control.
    * Emphasizes the benefits of automation, highlights cloud infrastructure support, and suggests specific tools for implementing a model training CI/CD system.
* [Application deployment and testing strategies (Google Cloud)](https://cloud.google.com/solutions/application-deployment-and-testing-strategies)
    * Best Practices: 1) Backward compatibility 2) Continuous integration/continuous deployment (CI/CD) 3) Automation 4) Operating environments and configuration management. 5) Rollback strategy in case things go wrong 6) Post-deployment monitoring
* [Leveraging TensorFlow-TensorRT integration for Low latency Inference](https://blog.tensorflow.org/2021/01/leveraging-tensorflow-tensorrt-integration.html):TensorRT integration in TensorFlow allows developers to optimize and accelerate their deep learning models for deployment on GPUs. By leveraging TensorRT's optimizations, TensorFlow users can achieve faster inference times and reduced memory footprint. This integration provides a seamless workflow, enabling efficient deployment of TensorFlow models with improved performance for real-time applications.
     
### Large-Language Models
* [Parameter-Efficient Transfer Learning for NLP](http://proceedings.mlr.press/v97/houlsby19a/houlsby19a.pdf)
* [RLHF: Reinforcement Learning from Human Feedback (A blog by Chip Huyen)](https://huyenchip.com/2023/05/02/rlhf.html)
* [StackLLaMA: A hands-on guide to train LLaMA with RLHF](https://huggingface.co/blog/stackllama)
