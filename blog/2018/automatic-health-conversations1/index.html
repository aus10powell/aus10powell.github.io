<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Automated Health Responses Part 1</title>
<meta name="description" content="Code for this project can be viewed at: Automated Health Responses Github">

<link rel="stylesheet" href="/css/main.css">
<link rel="canonical" href="https://aus10powell.github.io//blog/2018/automatic-health-conversations1/">
<link rel="alternate" type="application/rss+xml" title="Austin's Site" href="https://aus10powell.github.io//feed.xml" />

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>


</head>
<body>
  <header class="site-header">
  <div class="container">
    <input type="checkbox" id="toggleNavbar">
    <!--<h1 class="logo"><a href="/">end2<span>end</span> <small>v2.0</small></a></h1>
    <label for="toggleNavbar" role="button" class="toggle-navbar-button">
      <i class="icon icon-menu"></i>
      <i class="icon icon-cross"></i>
    -->
    </label>
    <nav class="navbar">
      <ul>
        <li><a href="/" title="Home">Home</a></li>
        
          <li><a href="/about" title="About">About</a></li>
        
          <li><a href="/blog" title="Blog">Blog</a></li>
        
        <!--
        <li><a href="https://github.com/aus10powell/archive/master.zip" title="Download">Download</a></li>
        -->
        <li><a href="/feed.xml" target="_blank"><i class="icon icon-rss"></i></a></li>

      </ul>
    </nav>
  </div>
</header>


<main class="main-container">
  <div class="container">
    <article role="article" class="post">

  <div class="card">
    <header class="post-header">
      <h1 class="post-title">Automated Health Responses Part 1</h1>
      <em class="post-meta">
        <time>Aug 26, 2018</time>
      </em>
    </header>

    <div class="post-content">
      
        <figure class="post-thumbnail ">
          <img src="../../../images/2018-08-26-automatic-health-conversations1/thumbnail.jpeg" alt="Automated Health Responses Part 1">
        </figure>
      
      <p><em>Code for this project can be viewed at: <a href="https://github.com/aus10powell/Automated-Health-Responses">Automated Health Responses Github</a></em></p>

<h2 id="intro">Intro</h2>

<p>This is a proof-of-concept in generating appropriate responses to health-related questions. The general idea is that it could be part of a full-scale interaction between a healthcare professional and someone in need of healthcare. While the method of interaction (online, email, face-to-face) certainly would make a difference in how you went about any prototype, it is very important to have some sort of minimal viable product to demonstrate approach.</p>

<p>It is very much a bootstrapped initiative: what can be safely shown to any audience about providing appropriate responses. Of courses, the golden standard would be to have an AI system that interacted with you at least on some way relative and complementary to how a doctor might. But this a very layered and complex problem. Typically attacking it is trying to reduce this to simpler problem might be something like: given statement or query about my health, what is an appropriate response from a clinician?  This might be a step in a system some day from the likes of Google voice or Alexa after they determine you are talking about your health of course.</p>

<h4 id="general-approaches-to-machine-generated-conversational-responses">General approaches to machine generated conversational responses</h4>
<ul>
  <li>
    <p><u>Rule-base:</u> This is along the lines of: given a serious question about heart attack. Tell them to call 911. Not robust. Hard to maintain. Etc…</p>
  </li>
  <li><u>Generative:</u> Also called auto-encounters and basically the way an auto-translate service works. Given a sequence of characters or tokens. Predict the following sequence of tokens or characters. Not the best choice for this project largely because although some amazing advances have been made. It is very much to random especially in a medical context with often sparsely used words.</li>
  <li>
    <p><u>Selective:</u> There are many different approaches here. But generally speaking,  so far it the most most robust and time tested. Basically you want to select the best response (or best set of response) using a classified of sorts (more on that later) from a bank of potential responses.</p>

    <p>This seemed like the appropriate choice. Best of the rule-based and generative. Also gives clinicians the ability to exert control over response by deciding on which of the top response to select. Also, from which bank of response to choose from in the first place. This led to the well-known paper The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems <a href="https://arxiv.org/pdf/1506.08909.pdf">(here)</a> which introduces Ubuntu data to model appropriate responses to technical questions on a public forum. Coincidentally, the dataset that I had chosen was also based on public forum data, Reddit’s AskDocs Forum <a href="https://www.reddit.com/r/AskDocs/">(here)</a>.</p>
  </li>
</ul>

<h2 id="dataset-description">Dataset Description</h2>
<p>The online forum Reddit has a sub-forum (“subreddit”) called “AskDocs” where certified health professionals reply to questions by other forum members. The health professionals could be anyone from health students, nurses, to residents, to full-scale general practitioners, but had to provide evidence of their status to reddit moderators and can be identified as such. The data is updated and stored in <a href="https://cloud.google.com/bigquery/public-data/">Google’s BigQuery</a>, however if you wish to download the data I used you can do directly at <a href="https://storage.googleapis.com/health-conversations.appspot.com/2014_2017_askDocs.gz">this link</a>.</p>

<h4 id="formatting-data">Formatting data</h4>
<p>In order to model forum data the form of a query and response, the authors of the Ubuntu paper had to estimate (using a time window) to dictate whether a new post was in direct response to a previous post. With the Reddit data, the same approach certainly could have been applied, however in Reddit it is explicit whether a new post under a thread (an ongoing conversation concerning a topic started by the original post) is in direct response to the original post or in response to another comment. Also, per the paper’s recommendation, only threads with at least 3 posts were retained in order to provide context. Total this generated 955,610 samples of unique 282,433 words which was split into train/test/validate 80/10/10 respectively:</p>

<figure>
<img src="../../../images/2018-08-26-automatic-health-conversations1/askDocs.png" alt="askDocs example" style="width:500px;" border="5" />
<figcaption> Sample thread post start</figcaption>
</figure>

<p>A key way of measuring how dynamic a conversation is in a thread is counting the number of turns in a conversation (or thread). Turns refer to the switching between speakers. This is follows the assumption for human-like chatbots that conversation partners take turns in a conversation (or thread). Given that most of the posts in AskDocs only generate around 4-5 posts it is a safe assumption to say that all posts following that initial post are generally on the same topic. (great Medium post <a href="https://chatbotsjournal.com/designing-for-conversational-ui-humanizing-chatbots-f199e59b363e">here</a> on humanizing your chatbot)</p>

<figure>
 <img src="../../../images/2018-08-26-automatic-health-conversations1/turns_per_thread.png" alt="turns per thread" style="width:700px;" />
<figcaption> Distribution of number of turns per AskDocs Forum thread</figcaption>
</figure>

<h2 id="the-model">The Model</h2>
<p>I start with code provided in <a href="https://basmaboussaha.wordpress.com/2017/10/18/implementation-of-dual-encoder-using-keras/">this excellent blog: Implementation of dual encoder using Keras</a>, updating some of the code for my needs. I recommend reading the blog and paper it is based on. Although the model can train embeddings as it goes along, both the 6B token and 840B token Glove embeddings were tested with substantial improvements made with the 840B tokens. Embeddings built on all 2015 reddit comments were also tested but with no decrease in loss.</p>

<figure>
 <img src="../../../images/2018-08-26-automatic-health-conversations1/dual_encoder_model_architecture.png" alt="turns per thread" style="width:700px;" />
</figure>

<p>The key structural advantage of this model is</p>

<p>which in Keras is defined as a sequential model then embedding layer which is initialized with the GLoVe embeddings. I chose to allow these embeddings to be trained further during training process.</p>

<h3 id="results">Results</h3>
<figure>
 <img src="../../../images/2018-08-26-automatic-health-conversations1/model_scores1.png" alt="turns per thread" style="width:700px;" />
</figure>

<h3 id="conclusion">Conclusion</h3>
<p>This project was largely attempting to duplicate the original Ubuntu Dual Encoder paper for health data. Comparison of base metrics were quit similar to original paper with minimal effort in tuning model and adjusting parsing of data. One key difference in this implementation of that paper was the omission of comments previous to a given query to give context in selecting response. The results from these data however are promising and suggest a worthwhile effort in creating a more satisfying and health-centric responses.</p>

<h3 id="papers">Papers</h3>

<ul>
  <li>Diagnosing Disease: <a href="http://matjournals.in/index.php/JoWDWD/article/view/2334/1613">A Self-Diagnosis Medical Chatbot Using Artificial Intelligence</a></li>
  <li>Helped to decide on model for retrieval: <a href="https://arxiv.org/abs/1506.08909">The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems</a></li>
</ul>

<h2 id="future-work">Future Work</h2>

<h5 id="dataset-creation">Dataset creation</h5>
<ul>
  <li>There are a few changes to how the data was manipulated that might train a model for an appropriate response. For example the model currently is train on a response to every query so there can be multiple responses to the same query. Using something like the number of upvotes, one response could be selected (at least for the initial query).</li>
  <li>Conversation history in the thread could be include in the encoder portion of the model. This would potentially help the correct results so that we would be able to select the most relevant response given the history as opposed to a technically correct, but non-sensical result like the one below.</li>
</ul>
<figure>
 <img src="../../../images/2018-08-26-automatic-health-conversations1/answer_selection.png" alt="turns per thread" style="width:700px;" />
</figure>

<h5 id="refinement-of-health-purpose">Refinement of “Health” purpose</h5>
<p>Most of this work was towards creating an initial viable solution in human-like responses to a health-related statement or question. One way of refining the types of responses would be to determine what type of statement/questions started the conversation and score possible answers only within that concept space.</p>

    </div>

    
<hr>

<aside id="comments" class="disqus">
  <h3><i class="icon icon-comments-o"></i> Comments</h3>
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function() {
      this.page.url = 'https://aus10powell.github.io//blog/2018/automatic-health-conversations1/';
      this.page.identifier = '/blog/2018/automatic-health-conversations1';
    };
    (function() {
      var d = document,
      s = d.createElement('script');
      s.src = '//austins-site.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })
    ();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</aside>


  </div>

</article>

  </div>
</main>

<footer class="site-footer">
  <div class="container">
    <ul class="social">
  <li><a href="https://github.com/aus10powell" target="_blank"><i class="icon icon-github"></i></a></li>
  <li><a href="https://twitter.com/aus10_powers" target="_blank"><i class="icon icon-twitter"></i></a></li>
  <li><a href="https://www.linkedin.com/in/aus10powell/" target="_blank"><i class="icon icon-linkedin"></i></a></li>
</ul>

    <p class="txt-medium-gray">
      <small>&copy;2018 All rights reserved. Made with <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> and ♥</small>
    </p>
  </div>
</footer>


  <!--<a href="https://github.com/aus10powell" target="_blank" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#337ab7; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a> -->
</body>
</html>
